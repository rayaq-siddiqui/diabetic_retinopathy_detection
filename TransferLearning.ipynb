{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all resources loaded\n"
     ]
    }
   ],
   "source": [
    "# command to run the code\n",
    "# python TransferLearning.py --path 'kaggle/' --class_folders '[\"class0\",\"class1\",\"class2\",\"class3\",\"class4\"]' --dim 224 --lr 1e-4 --batch_size 16 --epochs 20 --initial_layers_to_freeze 10 --model InceptionV3 --folds 5 --outdir 'Transfer_Learning_DR/' --mode 'train'\n",
    "\n",
    "# data science libraries\n",
    "from unittest import result\n",
    "from xml.etree.ElementInclude import include\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# keras and tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalMaxPooling2D, GlobalAveragePooling2D, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import __version__ as keras_version\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# resources\n",
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import h5py\n",
    "import argparse\n",
    "import json\n",
    "import joblib\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# print validation statement\n",
    "print(\"all resources loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'kaggle/'\n",
    "class_folders = [\"class0\",\"class1\",\"class2\",\"class3\",\"class4\"]\n",
    "dim = 224\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "initial_layers_to_freeze = 10\n",
    "model = 'InceptionV3'\n",
    "folds = 5\n",
    "outdir = 'Transfer_Learning_DR/'\n",
    "mode = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# DEFINING FUNCTIONS\n",
    "# getting the image itself\n",
    "def get_im_cv2(path, dim=224):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (dim, dim), cv2.INTER_LINEAR)\n",
    "    return resized\n",
    "\n",
    "\n",
    "# preprocess the image based on the ImageNet pretrained model\n",
    "def pre_process(img):\n",
    "    img[:,:,0] = img[:,:,0] - 103.939\n",
    "    img[:,:,1] = img[:,:,1] - 116.779\n",
    "    img[:,:,2] = img[:,:,2] - 123.68\n",
    "    return img\n",
    "\n",
    "\n",
    "# function that builds the X,y into numpy format\n",
    "def read_data(class_folders, path, num_classes, dim, train_val='train'):\n",
    "    print(train_val)\n",
    "    train_X, train_y = [], []\n",
    "\n",
    "    for c in class_folders:\n",
    "        path_class = path + str(train_val) + '/' + str(c)\n",
    "        file_list = os.listdir(path_class)\n",
    "\n",
    "        for f in file_list:\n",
    "            img = get_im_cv2(path_class + '/' + str(f))\n",
    "            img = pre_process(img)\n",
    "            train_X.append(img)\n",
    "            train_y.append(int(c.split('class')[1]))\n",
    "\n",
    "    train_y = to_categorical(np.array(train_y), num_classes)\n",
    "\n",
    "    return np.array(train_X), train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "# we are going to be training the following three models using their pseudocode\n",
    "# we are going to train the inceptionV3 architecture here\n",
    "def inception_pseudo(dim=224, freeze_layers=30, full_freeze='N'):\n",
    "    model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(5, activation='softmax')(x)\n",
    "    model_final = Model(model.input, out)\n",
    "\n",
    "    if full_freeze != 'N':\n",
    "        for layer in model.layers[0:freeze_layers]:\n",
    "            layer.trainable = False\n",
    "    return model_final\n",
    "\n",
    "# we are going to train the resnet arhcitecture here\n",
    "def resnet_pseudo(dim=224,freeze_layers=10,full_freeze='N'):\n",
    "    model = ResNet50(weights='imagenet',include_top=False)\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(5,activation='softmax')(x)\n",
    "    model_final = Model(model.input, out)\n",
    "    if full_freeze != 'N':\n",
    "        for layer in model.layers[0:freeze_layers]:\n",
    "            layer.trainable = False\n",
    "    return model_final\n",
    "\n",
    "# we are going to train the VGG16 architecture here\n",
    "def VGG16_pseudo(dim=224,freeze_layers=10,full_freeze='N'):\n",
    "    model = VGG16(weights='imagenet',include_top=False)\n",
    "    x = model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(5,activation='softmax')(x)\n",
    "    model_final = Model(model.input, out)\n",
    "    if full_freeze != 'N':\n",
    "        for layer in model.layers[0:freeze_layers]:\n",
    "            layer.trainable = False\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_X, train_y, n_fold=5, batch_size=16, epochs=40, dim=224, lr=1e-5, model='ResNet50'):\n",
    "    model_save_dest = {}\n",
    "    k = 0\n",
    "    kf = KFold(n_splits=n_fold, random_state=0, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(train_X):\n",
    "        k += 1\n",
    "        X_train, X_test = train_X[train_index], train_X[test_index]\n",
    "        y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "\n",
    "        if model == 'Resnet50':\n",
    "                model_final = resnet_pseudo(dim=224,freeze_layers=10,full_freeze='N')\n",
    "\n",
    "        if model == 'VGG16':\n",
    "            model_final = VGG16_pseudo(dim=224,freeze_layers=10,full_freeze='N')\n",
    "\n",
    "        if model == 'InceptionV3':\n",
    "            model_final = inception_pseudo(dim=224,freeze_layers=10,full_freeze='N')\n",
    "\n",
    "        datagen = ImageDataGenerator(\n",
    "            horizontal_flip = True,\n",
    "            vertical_flip = True,\n",
    "            width_shift_range = 0.1,\n",
    "            height_shift_range = 0.1,\n",
    "            channel_shift_range = 0,\n",
    "            zoom_range = 0.2,\n",
    "            rotation_range = 20\n",
    "        )\n",
    "\n",
    "        adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n",
    "        model_final.compile(optimizer=adam, loss=[\"categorical_crossentropy\"], metrics=[\"accuracy\"])\n",
    "        reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.50, patience=3, min_lr=0.000001)\n",
    "\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1),\n",
    "            CSVLogger('keras-5fold-run-01-v1-epochs_ib.log', separator=',', append=False),\n",
    "            reduce_lr,\n",
    "            ModelCheckpoint(\n",
    "                'kera1-5fold-run-01-v1-fold-' + str('%02d' % (k + 1)) + '-run-' + str('%02d' % (1 + 1)) + '.check',\n",
    "                monitor='val_loss', mode='min',\n",
    "                save_best_only=True,\n",
    "                verbose=1\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # note the class weights - they play a part for the imbalanced data\n",
    "        model_final.fit_generator(\n",
    "            datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "            steps_per_epoch=X_train.shape[0]/batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test,y_test),\n",
    "            callbacks=callbacks,\n",
    "            class_weight={0:0.012,1:0.12,2:0.058,3:0.36,4:0.43}\n",
    "        )\n",
    "\n",
    "        model_name = 'kera1-5fold-run-01-v1-fold-' + str('%02d' % (k + 1)) + '-run-' + str('%02d' % (1 + 1)) + '.check'\n",
    "\n",
    "        del model_final\n",
    "        f = h5py.File(model_name, 'r+')\n",
    "        del f['optimizer_weights']\n",
    "        f.close()\n",
    "\n",
    "        model_final = tf.keras.models.load_model(model_name)\n",
    "        model_name1 = outdir + str(model) + '___' + str(k) \n",
    "        model_final.save(model_name1)\n",
    "        model_save_dest[k] = model_name1\n",
    "\n",
    "    return model_save_dest\n",
    "\n",
    "\n",
    "# inference function\n",
    "def inference_validation(test_X, test_y, model_save_dest, n_class=5, folds=5):\n",
    "    pred = np.zeros((len(test_X), n_class))\n",
    "\n",
    "    for k in range(1, folds+1):\n",
    "        model = tf.keras.load_model(model_save_dest[k])\n",
    "        pred = pred + model.predict(test_X)\n",
    "    pred = pred/(1.0*folds)\n",
    "    pred_class = np.argmax(pred,axis=1)\n",
    "    act_class = np.argmax(test_y,axis=1)\n",
    "    accuracy = np.sum([pred_class == act_class])*1.0/len(test_X)\n",
    "    kappa = cohen_kappa_score(pred_class,act_class,weights='quadratic')\n",
    "    return pred_class,accuracy,kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main process\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    num_classes = len(class_folders)\n",
    "\n",
    "    if mode == 'train':\n",
    "        print('Data Processing..')\n",
    "        file_list, labels = read_data(\n",
    "            class_folders,\n",
    "            path,\n",
    "            num_classes,\n",
    "            dim,\n",
    "            train_val='train'\n",
    "        )\n",
    "        print(len(file_list), len(labels))\n",
    "        print(labels[0], labels[-1])\n",
    "        model_save_dest = train_model(\n",
    "            file_list,\n",
    "            labels,\n",
    "            n_fold = folds,\n",
    "            batch_size=batch_size,\n",
    "            epochs = epochs,\n",
    "            dim = dim,\n",
    "            lr = lr,\n",
    "            model = model\n",
    "        )\n",
    "        joblib.dump(model_save_dest, f'{outdir}/model_dict.pkl')\n",
    "        print(\"Model saved to dest:\",model_save_dest)\n",
    "    else:\n",
    "        model_save_dest = joblib.load(model_save_dest)\n",
    "        print('Models loaded from:', model_save_dest)\n",
    "\n",
    "        # do inference/validation\n",
    "        test_files, test_y = read_data(\n",
    "            class_folders,\n",
    "            path,\n",
    "            num_classes,\n",
    "            dim,\n",
    "            train_val='validation'\n",
    "        )\n",
    "        test_X = []\n",
    "\n",
    "        for f in test_files:\n",
    "            img = get_im_cv2(f)\n",
    "            img = pre_process(img)\n",
    "            test_X.append(img)\n",
    "\n",
    "        test_X = np.array(test_X)\n",
    "        test_y = np.array(test_y)\n",
    "        print(test_X.shape)\n",
    "        print(test_y.shape)\n",
    "        pred_class, accuracy, kappa = inference_validation(\n",
    "            test_X,\n",
    "            test_y,\n",
    "            model_save_dest,\n",
    "            n_class=num_classes,\n",
    "            folds=folds\n",
    "        )\n",
    "        results_df = pd.DataFrame()\n",
    "        results_df['file_name'] = test_files\n",
    "        results_df['target'] = test_y\n",
    "        results_df['prediction'] = pred_class\n",
    "        results_df.to_csv(f'{outdir}/val_results_reg.csv', index=False)\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(\"Kappa score:\", kappa)\n",
    "        print(\"accuracy:\", accuracy)\n",
    "        print(\"End of training\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        print(\"Processing Time\",time.time() - start_time,' secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing..\n",
      "train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/my/4kvjzm3d3d5319_c0jk6mtx40000gn/T/ipykernel_464/451043146.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/my/4kvjzm3d3d5319_c0jk6mtx40000gn/T/ipykernel_464/377154936.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data Processing..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         file_list, labels = read_data(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mclass_folders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/4kvjzm3d3d5319_c0jk6mtx40000gn/T/ipykernel_464/1383054895.py\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(class_folders, path, num_classes, dim, train_val)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_im_cv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_class\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/my/4kvjzm3d3d5319_c0jk6mtx40000gn/T/ipykernel_464/1383054895.py\u001b[0m in \u001b[0;36mget_im_cv2\u001b[0;34m(path, dim)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# getting the image itself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_im_cv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3615c9c55406a73a1128a4884c827c033440f1425522ecff6a89f0ccf27bab2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('diabetic_retinopathy_detection-qJwFscop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
